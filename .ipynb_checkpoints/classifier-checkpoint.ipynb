{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1c41fafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6c89e7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "data_dir = 'dataset'\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(data_dir, train=True, download=True)\n",
    "test_dataset  = torchvision.datasets.MNIST(data_dir, train=False, download=True)\n",
    "\n",
    "train_transform = transforms.Compose([transforms.ToTensor(),])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.ToTensor(),])\n",
    "\n",
    "train_dataset.transform = train_transform\n",
    "test_dataset.transform = test_transform\n",
    "\n",
    "m=len(train_dataset)\n",
    "\n",
    "train_data, val_data = random_split(train_dataset, [int(m-m*0.2), int(m*0.2)])\n",
    "batch_size=256\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
    "valid_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0a51021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(28*28,64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64,64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64,10)\n",
    "        )\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7f0122a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(classifier, device, data_loader, loss, optimizer):\n",
    "    train_loss = []\n",
    "    for images,labels in data_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        #print(labels)\n",
    "        get_one_hot(labels,10)\n",
    "        #forward\n",
    "        estimated = classifier(images)\n",
    "        \n",
    "        #compute cost function\n",
    "        J = loss(estimated,labels)\n",
    "        \n",
    "        #get gradient: set accumulate to zero and calculate derivates dJ/dvar\n",
    "        optimizer.zero_grad()\n",
    "        J.backward()\n",
    "        \n",
    "        #step to the gradient direction\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(J.item())\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "def validation(classifier, device, data_loader, loss, optimizer):\n",
    "    with torch.no_grad():\n",
    "        conc_out = []\n",
    "        conc_label = []\n",
    "        val_loss = []\n",
    "        for images,labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            #forward\n",
    "            predicted = classifier(images)\n",
    "\n",
    "            #compute cost function\n",
    "            #conc_out.append(estimated.cpu())\n",
    "            #conc_label.append(labels.cpu())\n",
    "            val_loss.append(loss(predicted.cpu(), labels.cpu()))\n",
    "        # Create a single tensor with all the values in the lists\n",
    "        #conc_out = torch.cat(conc_out)\n",
    "        #conc_label = torch.cat(conc_label) \n",
    "        # Evaluate global loss\n",
    "        #val_loss = loss(conc_out, conc_label)\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "afaaed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ae_outputs(classifier,n=10):\n",
    "    targets = test_dataset.targets.numpy()\n",
    "    #categorize images respective to number 0 to 9\n",
    "    t_idx = {i:np.where(targets==i)[0][0] for i in range(n)}\n",
    "\n",
    "    for i in range(n):\n",
    "        #get the 0th image of number i\n",
    "        img = test_dataset[t_idx[i]][0].unsqueeze(0).to(device)\n",
    "        classifier.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            rec  = classifier(img)\n",
    "\n",
    "        print('image number',i,'predicted number',np.argmax(rec.squeeze().numpy()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1583c379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=64, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = Classifier()\n",
    "optimizer = optim.SGD(classifier.parameters(),lr=1e-2)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')\n",
    "\n",
    "# Move model to the selected device\n",
    "classifier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "99c33035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 1/5 \t train loss 2.1020133596785526 \t val loss 1.9492356777191162\n",
      "\n",
      " EPOCH 2/5 \t train loss 1.7054073931054865 \t val loss 1.4528179168701172\n",
      "\n",
      " EPOCH 3/5 \t train loss 1.2316213272353436 \t val loss 1.04625403881073\n",
      "\n",
      " EPOCH 4/5 \t train loss 0.9064906309259698 \t val loss 0.7994855642318726\n",
      "\n",
      " EPOCH 5/5 \t train loss 0.7169794291257858 \t val loss 0.6582539677619934\n",
      "image number 0 predicted number 0\n",
      "image number 1 predicted number 1\n",
      "image number 2 predicted number 2\n",
      "image number 3 predicted number 3\n",
      "image number 4 predicted number 4\n",
      "image number 5 predicted number 6\n",
      "image number 6 predicted number 2\n",
      "image number 7 predicted number 7\n",
      "image number 8 predicted number 2\n",
      "image number 9 predicted number 9\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "diz_loss = {'train_loss':[],'val_loss':[]}\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(classifier, device, train_loader, loss, optimizer)\n",
    "    val_loss = validation(classifier, device, valid_loader, loss, optimizer)\n",
    "    print('\\n EPOCH {}/{} \\t train loss {} \\t val loss {}'.format(epoch + 1, num_epochs,train_loss,np.mean(val_loss)))\n",
    "    diz_loss['train_loss'].append(train_loss)\n",
    "    diz_loss['val_loss'].append(np.mean(val_loss))\n",
    "\n",
    "plot_ae_outputs(classifier,n=10)\n",
    "test_loss = validation(classifier, device, test_loader, loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c55fe8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.6887),\n",
       " tensor(0.6200),\n",
       " tensor(0.6378),\n",
       " tensor(0.5960),\n",
       " tensor(0.6082),\n",
       " tensor(0.6198),\n",
       " tensor(0.6464),\n",
       " tensor(0.6044),\n",
       " tensor(0.6688),\n",
       " tensor(0.5553),\n",
       " tensor(0.6259),\n",
       " tensor(0.6618),\n",
       " tensor(0.7062),\n",
       " tensor(0.7042),\n",
       " tensor(0.5917),\n",
       " tensor(0.5695),\n",
       " tensor(0.6109),\n",
       " tensor(0.6455),\n",
       " tensor(0.6360),\n",
       " tensor(0.6614),\n",
       " tensor(0.7087),\n",
       " tensor(0.5937),\n",
       " tensor(0.6788),\n",
       " tensor(0.6898),\n",
       " tensor(0.6210),\n",
       " tensor(0.6433),\n",
       " tensor(0.5811),\n",
       " tensor(0.6424),\n",
       " tensor(0.5802),\n",
       " tensor(0.5900),\n",
       " tensor(0.6486),\n",
       " tensor(0.6193),\n",
       " tensor(0.6434),\n",
       " tensor(0.6045),\n",
       " tensor(0.6588),\n",
       " tensor(0.5910),\n",
       " tensor(0.6008),\n",
       " tensor(0.6281),\n",
       " tensor(0.6724),\n",
       " tensor(0.5607)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bf7635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
